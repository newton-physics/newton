{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentiable Simulation in Newton\n",
    "\n",
    "[![ Click here to deploy.](https://brev-assets.s3.us-west-1.amazonaws.com/nv-lb-dark.svg)](https://brev.nvidia.com/launchable/deploy?launchableID=env-35QaaoiXx6VDmVNBOEtmpLs9VBs)\n",
    "\n",
    "**Differentiable simulation** enables gradient-based optimization through physics simulations. This powerful technique allows you to:\n",
    "- Optimize control policies\n",
    "- Learn physical parameters\n",
    "- Design optimal trajectories\n",
    "- Train neural networks with physics constraints\n",
    "\n",
    "This tutorial demonstrates how to use Newton's differentiable simulation capabilities to optimize the initial velocity of a ball so that it bounces off walls and reaches a target position.\n",
    "\n",
    "## Problem Setup\n",
    "\n",
    "We'll optimize a ball's initial velocity so it:\n",
    "1. Bounces off a wall\n",
    "2. Bounces off the ground\n",
    "3. Lands at a target position\n",
    "\n",
    "The optimization uses **automatic differentiation** to compute gradients of the loss (distance to target) with respect to the initial velocity, then performs gradient descent to find the optimal trajectory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warp as wp\n",
    "import warp.render\n",
    "\n",
    "import newton\n",
    "import newton.examples\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "# Configure matplotlib for better plots\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Loss and Optimization Kernels\n",
    "\n",
    "First, we define Warp kernels for computing the loss and performing gradient descent updates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@wp.kernel\n",
    "def loss_kernel(pos: wp.array(dtype=wp.vec3), target: wp.vec3, loss: wp.array(dtype=float)):\n",
    "    \"\"\"Compute squared distance from particle to target.\"\"\"\n",
    "    delta = pos[0] - target\n",
    "    loss[0] = wp.dot(delta, delta)\n",
    "\n",
    "\n",
    "@wp.kernel\n",
    "def step_kernel(x: wp.array(dtype=wp.vec3), grad: wp.array(dtype=wp.vec3), alpha: float):\n",
    "    \"\"\"Perform gradient descent update.\"\"\"\n",
    "    tid = wp.tid()\n",
    "    x[tid] = x[tid] - grad[tid] * alpha\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Scene\n",
    "\n",
    "We'll create a scene with:\n",
    "- A particle (ball) with an initial velocity\n",
    "- A wall to bounce off\n",
    "- A ground plane\n",
    "- Contact parameters for realistic bouncing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation parameters\n",
    "fps = 60\n",
    "frame_dt = 1.0 / fps\n",
    "sim_steps = 36\n",
    "sim_substeps = 8\n",
    "sim_dt = frame_dt / sim_substeps\n",
    "\n",
    "# Target position for the ball\n",
    "target = wp.vec3(0.0, -2.0, 1.5)\n",
    "\n",
    "# Build the scene\n",
    "scene = newton.ModelBuilder(up_axis=newton.Axis.Z)\n",
    "\n",
    "# Add particle with initial position and velocity\n",
    "# Initial velocity is suboptimal - ball won't reach target\n",
    "initial_pos = wp.vec3(0.0, -0.5, 1.0)\n",
    "initial_vel = wp.vec3(0.0, 5.0, -5.0)\n",
    "scene.add_particle(pos=initial_pos, vel=initial_vel, mass=1.0)\n",
    "\n",
    "# Contact parameters for bouncing\n",
    "ke = 1.0e4  # Contact stiffness\n",
    "kf = 0.0    # Friction stiffness\n",
    "kd = 1.0e1  # Damping\n",
    "mu = 0.2    # Friction coefficient\n",
    "\n",
    "# Add wall (box shape)\n",
    "scene.add_shape_box(\n",
    "    body=-1,  # -1 means static (not attached to a body)\n",
    "    xform=wp.transform(wp.vec3(0.0, 2.0, 1.0), wp.quat_identity()),\n",
    "    hx=1.0, hy=0.25, hz=1.0,\n",
    "    cfg=newton.ModelBuilder.ShapeConfig(ke=ke, kf=kf, kd=kd, mu=mu),\n",
    ")\n",
    "\n",
    "# Add ground plane\n",
    "scene.add_ground_plane(cfg=newton.ModelBuilder.ShapeConfig(ke=ke, kf=kf, kd=kd, mu=mu))\n",
    "\n",
    "print(\"Scene created with:\")\n",
    "print(f\"  - 1 particle at {initial_pos}\")\n",
    "print(f\"  - Initial velocity: {initial_vel}\")\n",
    "print(f\"  - Target position: {target}\")\n",
    "print(f\"  - 1 wall and ground plane\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finalize Model with Gradient Support\n",
    "\n",
    "Key point: We use requires_grad=True to enable automatic differentiation through the simulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalize with gradient support\n",
    "model = scene.finalize(requires_grad=True)\n",
    "\n",
    "# Set contact parameters on the model\n",
    "model.soft_contact_ke = ke\n",
    "model.soft_contact_kf = kf\n",
    "model.soft_contact_kd = kd\n",
    "model.soft_contact_mu = mu\n",
    "model.soft_contact_restitution = 1.0  # Elastic collisions\n",
    "\n",
    "# Create solver\n",
    "solver = newton.solvers.SolverSemiImplicit(model)\n",
    "\n",
    "# Allocate states for the entire trajectory\n",
    "states = [model.state() for _ in range(sim_steps * sim_substeps + 1)]\n",
    "control = model.control()\n",
    "contacts = model.collide(states[0], soft_contact_margin=10.0)\n",
    "\n",
    "# Create loss array with gradient support\n",
    "loss = wp.zeros(1, dtype=wp.float32, requires_grad=True)\n",
    "\n",
    "print(f\"Model finalized with {model.particle_count} particles\")\n",
    "print(f\"Allocated {len(states)} state objects for trajectory\")\n",
    "print(f\"Gradient tracking enabled: {model.requires_grad}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Forward Simulation and Loss Computation\n",
    "\n",
    "The forward pass runs the simulation and computes the loss at the end.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_forward():\n",
    "    \"\"\"Run the forward simulation.\"\"\"\n",
    "    for sim_step in range(sim_steps):\n",
    "        for i in range(sim_substeps):\n",
    "            t = sim_step * sim_substeps + i\n",
    "            states[t].clear_forces()\n",
    "            solver.step(states[t], states[t + 1], control, contacts, sim_dt)\n",
    "\n",
    "def compute_loss():\n",
    "    \"\"\"Compute loss as squared distance to target.\"\"\"\n",
    "    loss.zero_()\n",
    "    wp.launch(loss_kernel, dim=1, inputs=[states[-1].particle_q, target, loss])\n",
    "    return loss.numpy()[0]\n",
    "\n",
    "def forward_pass():\n",
    "    \"\"\"Combined forward simulation and loss computation.\"\"\"\n",
    "    simulate_forward()\n",
    "    wp.launch(loss_kernel, dim=1, inputs=[states[-1].particle_q, target, loss])\n",
    "    return loss\n",
    "\n",
    "print(\"Forward simulation and loss functions defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Initial (Unoptimized) Trajectory\n",
    "\n",
    "Let's see how the ball behaves with the initial velocity before optimization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run initial simulation\n",
    "initial_loss = compute_loss()\n",
    "\n",
    "# Create viewer for initial trajectory\n",
    "viewer_initial = newton.viewer.ViewerRerun(\n",
    "    keep_historical_data=True\n",
    ")\n",
    "viewer_initial.set_model(model)\n",
    "\n",
    "# Log the initial trajectory\n",
    "frame = 0\n",
    "for i in range(0, len(states), sim_substeps):\n",
    "    state = states[i]\n",
    "    viewer_initial.begin_frame(frame * frame_dt)\n",
    "    viewer_initial.log_state(state)\n",
    "    # viewer_initial.log_contacts(contacts, state)\n",
    "    \n",
    "    # Log target as a small box\n",
    "    viewer_initial.log_shapes(\n",
    "        \"/target\",\n",
    "        newton.GeoType.BOX,\n",
    "        (0.1, 0.1, 0.1),\n",
    "        wp.array([wp.transform(target, wp.quat_identity())], dtype=wp.transform),\n",
    "        wp.array([wp.vec3(1.0, 0.0, 0.0)], dtype=wp.vec3),  # Red color\n",
    "    )\n",
    "    viewer_initial.end_frame()\n",
    "    frame += 1\n",
    "\n",
    "    print(state.particle_q.numpy())\n",
    "\n",
    "print(f\"Initial trajectory loss: {initial_loss:.4f}\")\n",
    "print(f\"Initial velocity: {states[0].particle_qd.numpy()[0]}\")\n",
    "print(f\"Final position: {states[-1].particle_q.numpy()[0]}\")\n",
    "print(f\"Target position: {target}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Optimization Loop\n",
    "\n",
    "Now we'll set up the gradient-based optimization using Warp's automatic differentiation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization parameters\n",
    "learning_rate = 0.02\n",
    "num_iterations = 100\n",
    "\n",
    "# Storage for optimization history\n",
    "loss_history = []\n",
    "velocity_history = []\n",
    "trajectory_history = []  # Store trajectories every N iterations\n",
    "\n",
    "# Reset to initial conditions\n",
    "states[0].particle_qd.assign(initial_vel)\n",
    "\n",
    "def optimization_step():\n",
    "    \"\"\"Perform one optimization iteration with gradient descent.\"\"\"\n",
    "    # Create tape for automatic differentiation\n",
    "    tape = wp.Tape()\n",
    "    \n",
    "    # Forward pass with gradient tracking\n",
    "    with tape:\n",
    "        forward_pass()\n",
    "    \n",
    "    # Backward pass to compute gradients\n",
    "    tape.backward(loss)\n",
    "    \n",
    "    # Get parameter and gradient\n",
    "    velocity_param = states[0].particle_qd\n",
    "    \n",
    "    # Gradient descent update\n",
    "    wp.launch(step_kernel, dim=len(velocity_param), \n",
    "              inputs=[velocity_param, velocity_param.grad, learning_rate])\n",
    "    \n",
    "    # Store history\n",
    "    current_loss = loss.numpy()[0]\n",
    "    current_vel = velocity_param.numpy()[0].copy()\n",
    "    loss_history.append(current_loss)\n",
    "    velocity_history.append(current_vel)\n",
    "    \n",
    "    # Clear gradients for next iteration\n",
    "    tape.zero()\n",
    "    \n",
    "    return current_loss, current_vel\n",
    "\n",
    "print(\"Optimization setup complete\")\n",
    "print(f\"Learning rate: {learning_rate}\")\n",
    "print(f\"Number of iterations: {num_iterations}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Optimization\n",
    "\n",
    "Now let's run the optimization and track intermediate trajectories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run optimization\n",
    "print(\"Starting optimization...\")\n",
    "print(f\"Initial loss: {loss_history[0] if loss_history else 'computing...'}\\n\")\n",
    "\n",
    "# Store trajectories every 10 iterations for visualization\n",
    "trajectory_sample_interval = 10\n",
    "\n",
    "for iteration in trange(num_iterations, desc=\"Optimizing\"):\n",
    "    current_loss, current_vel = optimization_step()\n",
    "    \n",
    "    # Store trajectory periodically\n",
    "    if iteration % trajectory_sample_interval == 0:\n",
    "        traj = []\n",
    "        for i in range(0, len(states), sim_substeps):\n",
    "            traj.append(states[i].particle_q.numpy()[0].copy())\n",
    "        trajectory_history.append((iteration, current_loss, traj))\n",
    "    \n",
    "    # Print progress every 20 iterations\n",
    "    if iteration % 20 == 0:\n",
    "        print(f\"Iter {iteration:3d}: Loss = {current_loss:.6f}, Velocity = {current_vel}\")\n",
    "\n",
    "# Final trajectory\n",
    "final_loss = loss_history[-1]\n",
    "final_vel = velocity_history[-1]\n",
    "final_pos = states[-1].particle_q.numpy()[0]\n",
    "\n",
    "print(f\"\\nOptimization complete!\")\n",
    "print(f\"Final loss: {final_loss:.6f}\")\n",
    "print(f\"Initial loss: {loss_history[0]:.6f}\")\n",
    "print(f\"Loss reduction: {(1 - final_loss/loss_history[0])*100:.1f}%\")\n",
    "print(f\"\\nFinal velocity: {final_vel}\")\n",
    "print(f\"Final position: {final_pos}\")\n",
    "print(f\"Target position: {target}\")\n",
    "print(f\"Distance to target: {np.linalg.norm(final_pos - np.array([target[0], target[1], target[2]])):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Loss Over Iterations\n",
    "\n",
    "Let's visualize how the loss decreased during optimization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Loss over iterations\n",
    "ax1.plot(loss_history, linewidth=2, color='#2E86AB')\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Loss (Squared Distance to Target)')\n",
    "ax1.set_title('Optimization Progress', fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_yscale('log')\n",
    "\n",
    "# Add annotations\n",
    "ax1.axhline(y=loss_history[0], color='r', linestyle='--', alpha=0.5, label='Initial')\n",
    "ax1.axhline(y=loss_history[-1], color='g', linestyle='--', alpha=0.5, label='Final')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot 2: Loss over iterations (linear scale, zoomed)\n",
    "ax2.plot(loss_history, linewidth=2, color='#A23B72')\n",
    "ax2.set_xlabel('Iteration')\n",
    "ax2.set_ylabel('Loss (Squared Distance to Target)')\n",
    "ax2.set_title('Optimization Progress (Linear Scale)', fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.fill_between(range(len(loss_history)), loss_history, alpha=0.3, color='#A23B72')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Loss decreased from {loss_history[0]:.6f} to {loss_history[-1]:.6f}\")\n",
    "print(f\"Reduction: {(1 - loss_history[-1]/loss_history[0])*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Optimized Trajectory with Intermediate Results\n",
    "\n",
    "Now let's create a comprehensive visualization showing:\n",
    "1. The final optimized trajectory\n",
    "2. Intermediate trajectories during optimization (colored by loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create viewer for optimized results\n",
    "viewer = newton.viewer.ViewerRerun(\n",
    "    keep_historical_data=True\n",
    ")\n",
    "viewer.set_model(model)\n",
    "\n",
    "# Log the final optimized trajectory with particle states\n",
    "frame = 0\n",
    "for i in range(0, len(states), sim_substeps):\n",
    "    state = states[i]\n",
    "    viewer.begin_frame(frame * frame_dt)\n",
    "    viewer.log_state(state)\n",
    "    viewer.log_contacts(contacts, state)\n",
    "    \n",
    "    # Log target\n",
    "    viewer.log_shapes(\n",
    "        \"/target\",\n",
    "        newton.GeoType.BOX,\n",
    "        (0.1, 0.1, 0.1),\n",
    "        wp.array([wp.transform(target, wp.quat_identity())], dtype=wp.transform),\n",
    "        wp.array([wp.vec3(1.0, 0.0, 0.0)], dtype=wp.vec3),  # Red\n",
    "    )\n",
    "    viewer.end_frame()\n",
    "    frame += 1\n",
    "\n",
    "# Now add intermediate trajectory lines colored by loss\n",
    "print(f\"\\nAdding {len(trajectory_history)} intermediate trajectories...\")\n",
    "\n",
    "# Find min/max loss for color mapping\n",
    "min_loss = min(traj[1] for traj in trajectory_history)\n",
    "max_loss = max(traj[1] for traj in trajectory_history)\n",
    "\n",
    "for iter_num, traj_loss, traj_points in trajectory_history:\n",
    "    # Convert trajectory to line segments\n",
    "    if len(traj_points) > 1:\n",
    "        starts = wp.array(traj_points[:-1], dtype=wp.vec3)\n",
    "        ends = wp.array(traj_points[1:], dtype=wp.vec3)\n",
    "        \n",
    "        # Color based on loss (blue = low loss, red = high loss)\n",
    "        color = warp.render.bourke_color_map(min_loss, max_loss, traj_loss)\n",
    "        \n",
    "        # Log trajectory line\n",
    "        viewer.begin_frame(0)  # Add to first frame\n",
    "        viewer.log_lines(\n",
    "            f\"/optimization/trajectory_{iter_num:03d}\",\n",
    "            starts,\n",
    "            ends,\n",
    "            color\n",
    "        )\n",
    "        viewer.end_frame()\n",
    "\n",
    "print(\"Visualization complete!\")\n",
    "print(f\"  - Final trajectory shown with particle animation\")\n",
    "print(f\"  - {len(trajectory_history)} intermediate trajectories shown as colored lines\")\n",
    "print(f\"  - Color mapping: Blue (low loss) â†’ Red (high loss)\")\n",
    "viewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Concepts\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "In this tutorial, we demonstrated differentiable simulation in Newton:\n",
    "\n",
    "1. **Model Setup with Gradients**\n",
    "   - Use `requires_grad=True` when finalizing the model\n",
    "   - This enables automatic differentiation through the entire simulation\n",
    "\n",
    "2. **Optimization Loop**\n",
    "   - Create a `wp.Tape()` to track operations\n",
    "   - Run forward simulation within the tape context\n",
    "   - Call `tape.backward(loss)` to compute gradients\n",
    "   - Update parameters using gradient descent\n",
    "\n",
    "3. **Key Components**\n",
    "   - **Loss function**: Measures how far we are from the goal\n",
    "   - **Forward pass**: Runs the simulation and computes loss\n",
    "   - **Backward pass**: Computes gradients via automatic differentiation\n",
    "   - **Parameter update**: Gradient descent to improve parameters\n",
    "\n",
    "### Results\n",
    "\n",
    "- **Initial loss**: Ball misses the target significantly\n",
    "- **Final loss**: Ball reaches very close to the target\n",
    "- **Optimization**: Gradients guide the velocity to create the perfect bounce trajectory\n",
    "\n",
    "### Applications\n",
    "\n",
    "Differentiable simulation enables:\n",
    "- **Trajectory optimization**: Find optimal paths through complex environments\n",
    "- **Parameter identification**: Learn physical properties from observations\n",
    "- **Control design**: Optimize control policies for robots\n",
    "- **Inverse problems**: Design systems that achieve desired behaviors\n",
    "- **Neural network training**: Use physics as a differentiable layer\n",
    "\n",
    "### Technical Details\n",
    "\n",
    "Newton uses **Warp's automatic differentiation** which:\n",
    "- Tracks all operations on arrays with `requires_grad=True`\n",
    "- Builds a computational graph during the forward pass\n",
    "- Computes gradients efficiently using reverse-mode AD (backpropagation)\n",
    "- Supports GPU acceleration for both forward and backward passes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "To explore more about differentiable simulation in Newton:\n",
    "\n",
    "1. **Try different optimization problems**:\n",
    "   - Optimize multiple parameters (position, velocity, mass)\n",
    "   - Multi-objective optimization (reach target while minimizing energy)\n",
    "   - Trajectory optimization for articulated robots\n",
    "\n",
    "2. **Explore other examples**:\n",
    "   - `example_diffsim_cloth.py`: Optimize cloth material parameters\n",
    "   - `example_diffsim_soft_body.py`: Learn soft body material properties\n",
    "   - `example_diffsim_drone.py`: Optimize drone control policies\n",
    "   - `example_diffsim_bear.py`: Optimize quadruped locomotion\n",
    "\n",
    "3. **Advanced techniques**:\n",
    "   - Use different optimizers (Adam, L-BFGS)\n",
    "   - Implement learning rate schedules\n",
    "   - Add regularization to prevent overfitting\n",
    "   - Combine with neural networks for learned controllers\n",
    "\n",
    "4. **Performance optimization**:\n",
    "   - Use CUDA graphs to accelerate repeated forward/backward passes\n",
    "   - Batch multiple optimization problems for parallel processing\n",
    "   - Profile gradient computation to identify bottlenecks\n",
    "\n",
    "Happy optimizing! ðŸŽ¯\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
